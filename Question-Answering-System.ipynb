{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3c76c-70d1-4ccd-bf80-cc572c01437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the libraries required\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9124bd-6f0a-47e6-b1b3-5b8420800297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('intern_screening_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21671f9-d4dd-4144-98ba-468ea6dbbc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataset into strings\n",
    "dataset['question'] = dataset['question'].astype(str)\n",
    "dataset['answer'] = dataset['answer'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c27871-3562-4f76-85e9-1adafb67f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd815526-938d-4739-973b-bf5db05bb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercasing the text\n",
    "    text = text.lower()\n",
    "    # Removing special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenizing the data\n",
    "    tokens = word_tokenize(text)\n",
    "    # Removing Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77631736-20b3-4d58-9b08-0c6b6ed88624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the cleaning function to the dataset\n",
    "dataset['question'] = dataset['question'].apply(clean_text)\n",
    "dataset['answer'] = dataset['answer'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b4e25b-82a6-4955-bcee-aeab51fc1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dataset['question'].values)\n",
    "questions_seq = tokenizer.texts_to_sequences(dataset['question'].values)\n",
    "answers_seq = tokenizer.texts_to_sequences(dataset['answer'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941acf3-8d65-4b78-9cdf-888d86b18085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences\n",
    "max_seqlen = 150\n",
    "questions_padded = pad_sequences(questions_seq, maxlen=max_seqlen)\n",
    "answers_padded = pad_sequences(answers_seq, maxlen=max_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10300c-e422-4984-9a32-d0f58a28eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(questions_padded, answers_padded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db239516-c1f6-4ad4-b55e-66e4224a38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "hidden_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3637b2-6c2a-4d7b-9ac6-718a16ab94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_seqlen,))\n",
    "encoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(hidden_units)(encoder_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ea1bf6-9cec-48a5-bb06-89481f4fc500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs = RepeatVector(max_seqlen)(encoder_lstm)\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True)(decoder_inputs)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')(decoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff2abf-14c3-4ec5-9634-2fbe70d86d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Model(encoder_inputs, decoder_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a833cb3-9a4a-476a-981f-34be4588aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25768ef8-c567-4a7c-bf61-1b4b443ea696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a54536-963b-4f88-bc8b-2cc2895caa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974c7c0-44ac-4a61-8a7f-2c2dcca31fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2429df-ad4c-4746-9ee0-7acd0f5a3398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate answers\n",
    "def generate_answer(question):\n",
    "    question_seq = tokenizer.texts_to_sequences([question])\n",
    "    question_padded = pad_sequences(question_seq, maxlen=max_seqlen)\n",
    "    print(f'Question sequence before padding: {question_seq}')\n",
    "    print(f'Padded question sequence: {question_padded}')\n",
    "    answer_seq = model.predict(question_padded)\n",
    "    print(f'Answer sequence predicted: {answer_seq}')\n",
    "    answer = ' '.join([tokenizer.index_word[word] for word in np.argmax(answer_seq, axis=-1)[0] if word != 0])\n",
    "    return answer\n",
    "\n",
    "# Example questions\n",
    "questions = [\n",
    "    \"What causes heart failure?\",\n",
    "    \"How to prevent Bronchitis?\",\n",
    "    \"What is Kidney Disease?\"\n",
    "]\n",
    "\n",
    "# Generate answers\n",
    "for question in questions:\n",
    "    generated_answer = generate_answer(question)\n",
    "    print(f'Question: {question}')\n",
    "    print(f'Generated Answer: {generated_answer}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
